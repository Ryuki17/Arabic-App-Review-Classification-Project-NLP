{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9w-R4U2gZQQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation splitting"
      ],
      "metadata": {
        "id": "9fAtHXiiZQjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "# 1) Load your CSV\n",
        "df = pd.read_csv('/content/App Reviews-SingleLabel-Multiclass.csv')\n",
        "\n",
        "# 2) Stratified splits: 80% train, 10% val, 10% test\n",
        "label_col = 'Label'\n",
        "# first split off 10% for test\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df[label_col],\n",
        "    random_state=777\n",
        ")\n",
        "# then split the 90% into 80/10\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.15,\n",
        "    stratify=train_val_df[label_col],\n",
        "    random_state=777\n",
        ")\n",
        "\n",
        "# 3) Save each split as CSV\n",
        "train_df.to_csv('train.csv', index=False)\n",
        "val_df.to_csv('val.csv', index=False)\n",
        "test_df.to_csv('test.csv', index=False)\n",
        "\n",
        "# 4) Display download links in notebook\n",
        "print(\"Download your splits:\")\n",
        "display(FileLink('train.csv'))\n",
        "display(FileLink('val.csv'))\n",
        "display(FileLink('test.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "HYfC9abMVYRu",
        "outputId": "29ed8b58-d5d9-461f-ce38-378e7c317877"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download your splits:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/train.csv"
            ],
            "text/html": [
              "<a href='train.csv' target='_blank'>train.csv</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/val.csv"
            ],
            "text/html": [
              "<a href='val.csv' target='_blank'>val.csv</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/test.csv"
            ],
            "text/html": [
              "<a href='test.csv' target='_blank'>test.csv</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-B [15 points]: Multiclass App Review Classification: from scratch"
      ],
      "metadata": {
        "id": "qhZf-GxkCnDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset analysis and report on important statistics."
      ],
      "metadata": {
        "id": "Lqr06n6vCpeB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JRTlhk7bCil8",
        "outputId": "4444b213-bcae-46ee-e2f0-0da13bacaff9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              review                Label\n",
              "0                                 يبيله تصليحات كثير           bug_report\n",
              "1                  ماتحملت ابدددددا ونا دفعت فلوس 🤔😕               rating\n",
              "2  اتمنى منكم عمل خيار لتفضيل المسلسل بالكامل عوض...  improvement_request\n",
              "3      ممتاز وبسيط وتشغيله لا يؤثر على سرعة الانترنت               rating\n",
              "4                                تبين م لي ي تم ل يب               others"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5efd523-8de1-4d58-8044-3ad79f5ab13b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يبيله تصليحات كثير</td>\n",
              "      <td>bug_report</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ماتحملت ابدددددا ونا دفعت فلوس 🤔😕</td>\n",
              "      <td>rating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اتمنى منكم عمل خيار لتفضيل المسلسل بالكامل عوض...</td>\n",
              "      <td>improvement_request</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ممتاز وبسيط وتشغيله لا يؤثر على سرعة الانترنت</td>\n",
              "      <td>rating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>تبين م لي ي تم ل يب</td>\n",
              "      <td>others</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5efd523-8de1-4d58-8044-3ad79f5ab13b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b5efd523-8de1-4d58-8044-3ad79f5ab13b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b5efd523-8de1-4d58-8044-3ad79f5ab13b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d1e429ce-ccfa-493a-b71d-df92307d99bc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d1e429ce-ccfa-493a-b71d-df92307d99bc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d1e429ce-ccfa-493a-b71d-df92307d99bc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# we have data inbalance, we could upscale or downscale, it would be better to upscale\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0645\\u0627\\u062a\\u062d\\u0645\\u0644\\u062a \\u0627\\u0628\\u062f\\u062f\\u062f\\u062f\\u062f\\u0627 \\u0648\\u0646\\u0627 \\u062f\\u0641\\u0639\\u062a \\u0641\\u0644\\u0648\\u0633 \\ud83e\\udd14\\ud83d\\ude15\",\n          \"\\u062a\\u0628\\u064a\\u0646 \\u0645 \\u0644\\u064a \\u064a \\u062a\\u0645 \\u0644 \\u064a\\u0628\",\n          \"\\u0627\\u062a\\u0645\\u0646\\u0649 \\u0645\\u0646\\u0643\\u0645 \\u0639\\u0645\\u0644 \\u062e\\u064a\\u0627\\u0631 \\u0644\\u062a\\u0641\\u0636\\u064a\\u0644 \\u0627\\u0644\\u0645\\u0633\\u0644\\u0633\\u0644 \\u0628\\u0627\\u0644\\u0643\\u0627\\u0645\\u0644 \\u0639\\u0648\\u0636\\u0627\\u064b \\u0639\\u0646 \\u062a\\u0641\\u0636\\u064a\\u0644 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0627\\u062a \\u0641\\u0642\\u0637\\n\\u0648\\u0634\\u0643\\u0631\\u0627\\u064b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"rating\",\n          \"others\",\n          \"bug_report\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: 2900 rows, 2 columns\n",
            "\n",
            "Data types:\n",
            "review    object\n",
            "Label     object\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "review    0\n",
            "Label     0\n",
            "dtype: int64\n",
            "\n",
            "Review length summary:\n",
            "count    2900.000000\n",
            "mean       74.374828\n",
            "std        87.071689\n",
            "min        10.000000\n",
            "25%        34.000000\n",
            "50%        52.000000\n",
            "75%        85.000000\n",
            "max      3023.000000\n",
            "Name: review_length, dtype: float64\n",
            "       review_length\n",
            "count    2900.000000\n",
            "mean       74.374828\n",
            "std        87.071689\n",
            "min        10.000000\n",
            "25%        34.000000\n",
            "50%        52.000000\n",
            "75%        85.000000\n",
            "max      3023.000000\n",
            "\n",
            "Class distribution:\n",
            "Label\n",
            "rating                 1298\n",
            "bug_report              756\n",
            "improvement_request     442\n",
            "others                  404\n",
            "Name: count, dtype: int64\n",
            "Label\n",
            "rating                 0.447586\n",
            "bug_report             0.260690\n",
            "improvement_request    0.152414\n",
            "others                 0.139310\n",
            "Name: proportion, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# read csv into data frame\n",
        "df = pd.read_csv('/content/App Reviews-SingleLabel-Multiclass.csv')\n",
        "display(df.head())\n",
        "# Basic dataset info\n",
        "print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Review‐length feature\n",
        "df['review_length'] = df['review'].str.len()\n",
        "print(\"\\nReview length summary:\")\n",
        "print(df['review_length'].describe())\n",
        "\n",
        "# Provide numeric and categorical summaries.\n",
        "print(df.describe())\n",
        "\n",
        "# view class balance\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['Label'].value_counts())\n",
        "# view class balance as precentage\n",
        "print(df['Label'].value_counts(normalize=True))\n",
        "\n",
        "# Plot review length histogram\n",
        "plt.figure()\n",
        "df['review_length'].hist(bins=100)\n",
        "plt.title('Histogram of Review Length')\n",
        "plt.xlabel('Characters')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# we have a review with 3023 charecters, we could remove it.\n",
        "# we have data inbalance, we could upscale or downscale, it would be better to upscale"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a from-scratch model\n",
        "o (RNN-based model: LSTM/GRU/Bidirectional/stacked/…)"
      ],
      "metadata": {
        "id": "ixi42gfKCqlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout, Conv1D, GlobalMaxPooling1D, SpatialDropout1D, MaxPooling1D, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import pickle\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "l-7xQjjKgbup"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation & report\n",
        "def eval_and_report(model, seq, true_y, label_encoder):\n",
        "    preds = np.argmax(model.predict(seq), axis=1)\n",
        "    print(classification_report(true_y, preds,\n",
        "          target_names=label_encoder.classes_))\n",
        "    cm = confusion_matrix(true_y, preds)\n",
        "    print(\"Confusion matrix:\\n\", cm)"
      ],
      "metadata": {
        "id": "7Oatg3DShclU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the word embeddings from scratch"
      ],
      "metadata": {
        "id": "zfHJDmtgCsit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "#y = le.fit_transform(labels)\n",
        "\n",
        "df_train = pd.read_csv('train.csv')\n",
        "print(\"Augmented data shape: \",df_train.shape)\n",
        "# 2) Extract texts and labels\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = le.fit_transform(df_train['Label'])\n",
        "\n",
        "df_val = pd.read_csv('val.csv')\n",
        "# 2) Extract texts and labels\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = le.transform(df_val['Label'])\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "# 2) Extract texts and labels\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = le.transform(df_test['Label'])\n",
        "\n",
        "# Tokenize\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN   = 600\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "val_seq   = pad_sequences(tokenizer.texts_to_sequences(X_val),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# Model A: embeddings from scratch + Bi-LSTM\n",
        "model_scratch = Sequential([\n",
        "    Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense( len(le.classes_), activation='softmax')\n",
        "])\n",
        "model_scratch.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "model_scratch.summary()\n",
        "\n",
        "# Train Model A\n",
        "history_a = model_scratch.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "emb_matrix = model_scratch.layers[0].get_weights()[0]\n",
        "print(\"Embedding matrix shape:\", emb_matrix.shape)  # -> (vocab_size, embed_dim)\n",
        "\n",
        "# save it to disk\n",
        "np.save('scratch_embeddings.npy', emb_matrix)\n",
        "\n",
        "# save your tokenizer\n",
        "with open('tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "print(\"=== Model A (scratch) ===\")\n",
        "eval_and_report(model_scratch, test_seq, y_test, le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "LzbXFRtnCtqT",
        "outputId": "5a157a1e-7df5-4898-cc39-06f7520728c6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_16 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_23                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_23                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.4255 - loss: 1.3094 - val_accuracy: 0.4483 - val_loss: 1.2291\n",
            "Epoch 2/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.5011 - loss: 1.1804 - val_accuracy: 0.5805 - val_loss: 1.0864\n",
            "Epoch 3/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6569 - loss: 0.8925 - val_accuracy: 0.6351 - val_loss: 0.9528\n",
            "Epoch 4/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8142 - loss: 0.5723 - val_accuracy: 0.6552 - val_loss: 0.9245\n",
            "Epoch 5/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9233 - loss: 0.3151 - val_accuracy: 0.6408 - val_loss: 1.1443\n",
            "Epoch 6/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9669 - loss: 0.1543 - val_accuracy: 0.6351 - val_loss: 1.2224\n",
            "Epoch 7/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9897 - loss: 0.0790 - val_accuracy: 0.6063 - val_loss: 1.3191\n",
            "Embedding matrix shape: (20000, 128)\n",
            "=== Model A (scratch) ===\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "         bug_report       0.64      0.75      0.69       151\n",
            "improvement_request       0.50      0.31      0.38        88\n",
            "             others       0.56      0.33      0.42        81\n",
            "             rating       0.70      0.81      0.75       260\n",
            "\n",
            "           accuracy                           0.65       580\n",
            "          macro avg       0.60      0.55      0.56       580\n",
            "       weighted avg       0.63      0.65      0.63       580\n",
            "\n",
            "Confusion matrix:\n",
            " [[113   7   8  23]\n",
            " [ 15  27   9  37]\n",
            " [ 14   8  27  32]\n",
            " [ 34  12   4 210]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with augmentations"
      ],
      "metadata": {
        "id": "0pFdncz3ZcMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "#y = le.fit_transform(labels)\n",
        "\n",
        "df_train = pd.read_csv('train_augmented.csv')\n",
        "print(\"Augmented data shape: \",df_train.shape)\n",
        "# 2) Extract texts and labels\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = le.fit_transform(df_train['Label'])\n",
        "\n",
        "df_val = pd.read_csv('val.csv')\n",
        "# 2) Extract texts and labels\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = le.transform(df_val['Label'])\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "# 2) Extract texts and labels\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = le.transform(df_test['Label'])\n",
        "\n",
        "# Tokenize\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN   = 600\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "val_seq   = pad_sequences(tokenizer.texts_to_sequences(X_val),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test),\n",
        "                          maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# Model A: embeddings from scratch + Bi-LSTM\n",
        "model_scratch = Sequential([\n",
        "    Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense( len(le.classes_), activation='softmax')\n",
        "])\n",
        "model_scratch.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "model_scratch.summary()\n",
        "\n",
        "# Train Model A\n",
        "history_a = model_scratch.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "emb_matrix = model_scratch.layers[0].get_weights()[0]\n",
        "print(\"Embedding matrix shape:\", emb_matrix.shape)  # -> (vocab_size, embed_dim)\n",
        "\n",
        "# save it to disk\n",
        "np.save('scratch_embeddings_aug.npy', emb_matrix)\n",
        "\n",
        "# save your tokenizer\n",
        "with open('tokenizer_aug.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "# Evaluation & report\n",
        "def eval_and_report(model, seq, true_y, label_encoder):\n",
        "    preds = np.argmax(model.predict(seq), axis=1)\n",
        "    print(classification_report(true_y, preds,\n",
        "          target_names=label_encoder.classes_))\n",
        "    cm = confusion_matrix(true_y, preds)\n",
        "    print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "print(\"=== Model A (scratch) ===\")\n",
        "eval_and_report(model_scratch, test_seq, y_test, le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 879
        },
        "id": "wft4RwH8ZbQY",
        "outputId": "d68e7622-1acd-4992-b4dc-e1ad1ee19f76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmented data shape:  (4800, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_18 (\u001b[38;5;33mEmbedding\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_25                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_25                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 48ms/step - accuracy: 0.5374 - loss: 1.1711 - val_accuracy: 0.6063 - val_loss: 1.0015\n",
            "Epoch 2/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.8814 - loss: 0.3401 - val_accuracy: 0.6638 - val_loss: 0.8879\n",
            "Epoch 3/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9547 - loss: 0.1762 - val_accuracy: 0.6810 - val_loss: 0.8605\n",
            "Epoch 4/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9891 - loss: 0.0607 - val_accuracy: 0.6782 - val_loss: 0.9273\n",
            "Epoch 5/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9947 - loss: 0.0279 - val_accuracy: 0.6782 - val_loss: 1.0841\n",
            "Epoch 6/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9991 - loss: 0.0132 - val_accuracy: 0.6753 - val_loss: 1.2550\n",
            "Embedding matrix shape: (20000, 128)\n",
            "=== Model A (scratch) ===\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "         bug_report       0.70      0.70      0.70       151\n",
            "improvement_request       0.59      0.33      0.42        88\n",
            "             others       0.49      0.47      0.48        81\n",
            "             rating       0.69      0.80      0.74       260\n",
            "\n",
            "           accuracy                           0.66       580\n",
            "          macro avg       0.62      0.58      0.59       580\n",
            "       weighted avg       0.65      0.66      0.65       580\n",
            "\n",
            "Confusion matrix:\n",
            " [[106   7  11  27]\n",
            " [ 11  29  10  38]\n",
            " [ 10   5  38  28]\n",
            " [ 25   8  19 208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use precomputed embeddings (similar to word2vec or Glove for Arabic)"
      ],
      "metadata": {
        "id": "NyTb1g0HCt_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ensuring Gensim works"
      ],
      "metadata": {
        "id": "jStC1fKLO-AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade gensim\n",
        "!clear"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax169XAn88er",
        "outputId": "898c29fc-08b1-4c2e-ea06-01c330dbc47d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.2\n",
            "    Uninstalling scipy-1.15.2:\n",
            "      Successfully uninstalled scipy-1.15.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n",
            "\u001b[H\u001b[2J"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download AraVec embedding\n",
        "!wget \"https://archive.org/download/aravec2.0/tweet_cbow_300.zip\"\n",
        "!unzip \"tweet_cbow_300.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brkz2xqU-e2k",
        "outputId": "d03e80a9-aea1-46de-b528-415c447f95d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-10 19:36:16--  https://archive.org/download/aravec2.0/tweet_cbow_300.zip\n",
            "Resolving archive.org (archive.org)... 207.241.224.2\n",
            "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ia803107.us.archive.org/0/items/aravec2.0/tweet_cbow_300.zip [following]\n",
            "--2025-05-10 19:36:16--  https://ia803107.us.archive.org/0/items/aravec2.0/tweet_cbow_300.zip\n",
            "Resolving ia803107.us.archive.org (ia803107.us.archive.org)... 207.241.232.157\n",
            "Connecting to ia803107.us.archive.org (ia803107.us.archive.org)|207.241.232.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 746111232 (712M) [application/zip]\n",
            "Saving to: ‘tweet_cbow_300.zip’\n",
            "\n",
            "tweet_cbow_300.zip  100%[===================>] 711.55M  10.6MB/s    in 46s     \n",
            "\n",
            "2025-05-10 19:37:02 (15.6 MB/s) - ‘tweet_cbow_300.zip’ saved [746111232/746111232]\n",
            "\n",
            "Archive:  tweet_cbow_300.zip\n",
            "  inflating: tweets_cbow_300         \n",
            "  inflating: tweets_cbow_300.trainables.syn1neg.npy  \n",
            "  inflating: tweets_cbow_300.wv.vectors.npy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# 1) Load your pre‐trained Word2Vec model\n",
        "w2v_model = gensim.models.Word2Vec.load('tweets_cbow_300')\n",
        "le = LabelEncoder()\n",
        "\n",
        "df_train = pd.read_csv('train.csv')\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = le.fit_transform(df_train['Label'])\n",
        "\n",
        "df_val = pd.read_csv('val.csv')\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = le.transform(df_val['Label'])\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = le.transform(df_test['Label'])\n",
        "\n",
        "# 2) Cleaning / normalizing function (as you provided)\n",
        "import re\n",
        "def clean_str(text):\n",
        "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",\n",
        "              '\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n','\\t','&quot;','?','؟','!']\n",
        "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n",
        "               \"\",\"\",\"\",\"\",\"ي\",\"\",' ',' ',' ',' ? ',' ؟ ',' ! ']\n",
        "    # remove tashkeel\n",
        "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', \"\", text)\n",
        "    # collapse repeated chars\n",
        "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text)\n",
        "    # simple normalizations\n",
        "    text = text.replace('وو','و').replace('يي','ي').replace('اا','ا')\n",
        "    for s, r in zip(search, replace):\n",
        "        text = text.replace(s, r)\n",
        "    return text.strip()\n",
        "\n",
        "# 3) Apply cleaning before tokenization\n",
        "X_train = [ clean_str(t) for t in X_train ]\n",
        "X_val   = [ clean_str(t) for t in X_val ]\n",
        "X_test  = [ clean_str(t) for t in X_test ]\n",
        "\n",
        "# (re‐tokenize & pad your sequences here, if needed)\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN   = 600\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen=MAX_LEN, padding='post')\n",
        "val_seq   = pad_sequences(tokenizer.texts_to_sequences(X_val),maxlen=MAX_LEN, padding='post')\n",
        "test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# 4) Build the embedding matrix from the gensim model\n",
        "embed_dim   = w2v_model.vector_size\n",
        "word_index  = tokenizer.word_index\n",
        "num_tokens  = min(332000, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_tokens, embed_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= num_tokens:\n",
        "        continue\n",
        "    if word in w2v_model.wv.key_to_index:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "    else:\n",
        "        # OOV words: you can leave as zeros or random‐initialize\n",
        "        embedding_matrix[i] = np.random.normal(size=(embed_dim,))\n",
        "\n",
        "# 5) Define & compile Model B using these embeddings\n",
        "model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=num_tokens,\n",
        "        output_dim=embed_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=MAX_LEN,\n",
        "        trainable=False\n",
        "    ),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "model_pretrained.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "model_pretrained.summary()\n",
        "\n",
        "# Train Model A\n",
        "history_b = model_pretrained.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"\\n=== Model B (pre-trained embeddings) ===\")\n",
        "eval_and_report(model_pretrained, test_seq, y_test, le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        },
        "id": "gEDPr--vCvH-",
        "outputId": "386c3e1c-cac5-4b93-ccce-8d1bf371b4fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m2,568,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,568,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,568,600\u001b[0m (9.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,568,600</span> (9.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,568,600\u001b[0m (9.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,568,600</span> (9.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.4462 - loss: 1.2359 - val_accuracy: 0.5891 - val_loss: 1.0244\n",
            "Epoch 2/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.6586 - loss: 0.9221 - val_accuracy: 0.6408 - val_loss: 0.9004\n",
            "Epoch 3/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7153 - loss: 0.7638 - val_accuracy: 0.6638 - val_loss: 0.8446\n",
            "Epoch 4/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7779 - loss: 0.6308 - val_accuracy: 0.6868 - val_loss: 0.8155\n",
            "Epoch 5/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8204 - loss: 0.5187 - val_accuracy: 0.6638 - val_loss: 0.8327\n",
            "Epoch 6/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8454 - loss: 0.4440 - val_accuracy: 0.6839 - val_loss: 0.8187\n",
            "Epoch 7/20\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8825 - loss: 0.3722 - val_accuracy: 0.6839 - val_loss: 0.8382\n",
            "\n",
            "=== Model B (pre-trained embeddings) ===\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "         bug_report       0.69      0.75      0.72       151\n",
            "improvement_request       0.59      0.55      0.57        88\n",
            "             others       0.69      0.46      0.55        81\n",
            "             rating       0.76      0.83      0.79       260\n",
            "\n",
            "           accuracy                           0.71       580\n",
            "          macro avg       0.68      0.64      0.66       580\n",
            "       weighted avg       0.71      0.71      0.71       580\n",
            "\n",
            "Confusion matrix:\n",
            " [[113  11   5  22]\n",
            " [ 13  48   4  23]\n",
            " [ 15   7  37  22]\n",
            " [ 22  15   8 215]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With augmentation"
      ],
      "metadata": {
        "id": "sX8CAKCIenik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# 1) Load your pre‐trained Word2Vec model\n",
        "w2v_model = gensim.models.Word2Vec.load('tweets_cbow_300')\n",
        "le = LabelEncoder()\n",
        "\n",
        "df_train = pd.read_csv('train_augmented.csv')\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = le.fit_transform(df_train['Label'])\n",
        "\n",
        "df_val = pd.read_csv('val.csv')\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = le.transform(df_val['Label'])\n",
        "\n",
        "df_test = pd.read_csv('test.csv')\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = le.transform(df_test['Label'])\n",
        "\n",
        "# 2) Cleaning / normalizing function (as you provided)\n",
        "import re\n",
        "def clean_str(text):\n",
        "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",\n",
        "              '\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n','\\t','&quot;','?','؟','!']\n",
        "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\n",
        "               \"\",\"\",\"\",\"\",\"ي\",\"\",' ',' ',' ',' ? ',' ؟ ',' ! ']\n",
        "    # remove tashkeel\n",
        "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', \"\", text)\n",
        "    # collapse repeated chars\n",
        "    text = re.sub(r'(.)\\1+', r\"\\1\\1\", text)\n",
        "    # simple normalizations\n",
        "    text = text.replace('وو','و').replace('يي','ي').replace('اا','ا')\n",
        "    for s, r in zip(search, replace):\n",
        "        text = text.replace(s, r)\n",
        "    return text.strip()\n",
        "\n",
        "# 3) Apply cleaning before tokenization\n",
        "X_train = [ clean_str(t) for t in X_train ]\n",
        "X_val   = [ clean_str(t) for t in X_val ]\n",
        "X_test  = [ clean_str(t) for t in X_test ]\n",
        "\n",
        "# (re‐tokenize & pad your sequences here, if needed)\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN   = 600\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train),maxlen=MAX_LEN, padding='post')\n",
        "val_seq   = pad_sequences(tokenizer.texts_to_sequences(X_val),maxlen=MAX_LEN, padding='post')\n",
        "test_seq  = pad_sequences(tokenizer.texts_to_sequences(X_test),maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# 4) Build the embedding matrix from the gensim model\n",
        "embed_dim   = w2v_model.vector_size\n",
        "word_index  = tokenizer.word_index\n",
        "num_tokens  = min(332000, len(word_index) + 1)\n",
        "embedding_matrix = np.zeros((num_tokens, embed_dim))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= num_tokens:\n",
        "        continue\n",
        "    if word in w2v_model.wv.key_to_index:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "    else:\n",
        "        # OOV words: you can leave as zeros or random‐initialize\n",
        "        embedding_matrix[i] = np.random.normal(size=(embed_dim,))\n",
        "\n",
        "# 5) Define & compile Model B using these embeddings\n",
        "model_pretrained = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=num_tokens,\n",
        "        output_dim=embed_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=MAX_LEN,\n",
        "        trainable=False\n",
        "    ),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(le.classes_), activation='softmax')\n",
        "])\n",
        "model_pretrained.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "\n",
        "model_pretrained.summary()\n",
        "\n",
        "# Train Model A\n",
        "history_b = model_pretrained.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=20,\n",
        "    batch_size=64,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"\\n=== Model B (pre-trained embeddings) ===\")\n",
        "eval_and_report(model_pretrained, test_seq, y_test, le)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 845
        },
        "id": "wUPULwA0enRw",
        "outputId": "212da864-6438-41ee-ae28-0de2c5358e54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │     \u001b[38;5;34m2,572,500\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,572,500</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,572,500\u001b[0m (9.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,572,500</span> (9.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,572,500\u001b[0m (9.81 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,572,500</span> (9.81 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 47ms/step - accuracy: 0.6998 - loss: 0.8134 - val_accuracy: 0.6810 - val_loss: 0.9014\n",
            "Epoch 2/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8724 - loss: 0.3575 - val_accuracy: 0.6609 - val_loss: 0.8492\n",
            "Epoch 3/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9078 - loss: 0.2524 - val_accuracy: 0.7098 - val_loss: 0.7869\n",
            "Epoch 4/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9369 - loss: 0.1903 - val_accuracy: 0.7011 - val_loss: 0.8145\n",
            "Epoch 5/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9503 - loss: 0.1583 - val_accuracy: 0.7011 - val_loss: 0.7952\n",
            "Epoch 6/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9622 - loss: 0.1266 - val_accuracy: 0.7040 - val_loss: 0.8292\n",
            "\n",
            "=== Model B (pre-trained embeddings) ===\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "         bug_report       0.69      0.77      0.73       151\n",
            "improvement_request       0.68      0.43      0.53        88\n",
            "             others       0.57      0.64      0.60        81\n",
            "             rating       0.79      0.80      0.80       260\n",
            "\n",
            "           accuracy                           0.72       580\n",
            "          macro avg       0.68      0.66      0.66       580\n",
            "       weighted avg       0.72      0.72      0.71       580\n",
            "\n",
            "Confusion matrix:\n",
            " [[116   5  12  18]\n",
            " [ 16  38   7  27]\n",
            " [ 15   3  52  11]\n",
            " [ 21  10  20 209]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification analysis and possible improvements."
      ],
      "metadata": {
        "id": "4_UkgLd9CvhY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEGjzNfyCwpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Possible improvements\n",
        "\"\"\"\n",
        "- **Hyperparameter tuning:** grid-search over LSTM hidden units, dropout rate, learning rate.\n",
        "- **Stacked RNNs or GRU:** try 2-layer LSTM/GRU or switch to GRU for faster training.\n",
        "- **Bidirectional & Attention:** add an attention layer on top of the RNN outputs.\n",
        "- **Fine-tuning embeddings:** set trainable=True for the Embedding layer in Model B.\n",
        "- **Data augmentation:** back-translation or synonym replacement on reviews.\n",
        "- **Class imbalance handling:** use class_weights or focal loss if your label counts are skewed.\n",
        "- **Ensemble:** average predictions of multiple architectures.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q1yHNQeWDWYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-C [15 points]: Multilabel App Review Classification: from scratch"
      ],
      "metadata": {
        "id": "lIGeS34uCyF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython.display import FileLink, display\n",
        "\n",
        "# 1) Load your CSV\n",
        "df = pd.read_csv('/content/App Reviews-Multilabel.csv')\n",
        "\n",
        "# 2) Stratified splits: 80% train, 10% val, 10% test\n",
        "#label_col = [\"bug_report\",\t\"improvement_request\",\t\"rating\",\t\"others\"]\n",
        "# first split off 10% for test\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=777\n",
        ")\n",
        "# then split the 90% into 80/10\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=0.15,\n",
        "    random_state=777\n",
        ")\n",
        "\n",
        "# 3) Save each split as CSV\n",
        "train_df.to_csv('train_multi.csv', index=False)\n",
        "val_df.to_csv('val_multi.csv', index=False)\n",
        "test_df.to_csv('test_multi.csv', index=False)\n",
        "\n",
        "# 4) Display download links in notebook\n",
        "print(\"Download your splits:\")\n",
        "display(FileLink('train_multi.csv'))\n",
        "display(FileLink('val_multi.csv'))\n",
        "display(FileLink('test_multi.csv'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "MvEmb5FWlEn9",
        "outputId": "687a7fa7-ca18-4ef2-97a4-fec55791f273"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download your splits:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/train_multi.csv"
            ],
            "text/html": [
              "<a href='train_multi.csv' target='_blank'>train_multi.csv</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/val_multi.csv"
            ],
            "text/html": [
              "<a href='val_multi.csv' target='_blank'>val_multi.csv</a><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "/content/test_multi.csv"
            ],
            "text/html": [
              "<a href='test_multi.csv' target='_blank'>test_multi.csv</a><br>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset analysis and report on important statistics."
      ],
      "metadata": {
        "id": "JQma3sz5C2N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "# read csv into data frame\n",
        "df = pd.read_csv('/content/App Reviews-Multilabel.csv')\n",
        "display(df.head())\n",
        "# # Print the dataset’s shape and a preview of the first rows.\n",
        "# print(df.shape)\n",
        "# # Show data types, non-null counts, and missing-value totals.\n",
        "# # check if thier is null data\n",
        "# print(df.isnull().sum())\n",
        "# Basic dataset info\n",
        "print(f\"Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "print(\"\\nData types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Review‐length feature\n",
        "df['review_length'] = df['review'].str.len()\n",
        "print(\"\\nReview length summary:\")\n",
        "print(df['review_length'].describe())\n",
        "\n",
        "# Provide numeric and categorical summaries.\n",
        "print(df.describe())\n",
        "\n",
        "# view class balance\n",
        "print(\"\\nClass distribution:\")\n",
        "bug_report_counts = df['bug_report'].sum()\n",
        "improvement_request_counts = df['improvement_request'].sum()\n",
        "rating_counts = df['rating'].sum()\n",
        "others_counts = df['others'].sum()\n",
        "print(bug_report_counts,\"bug_report\")\n",
        "print(improvement_request_counts,\"improvement_request\")\n",
        "print(rating_counts,\"rating\")\n",
        "print(others_counts,\"others\")\n",
        "\n",
        "# viewing class balance as precentage\n",
        "total_sum = bug_report_counts + improvement_request_counts + rating_counts + others_counts\n",
        "print(\"As precentages\")\n",
        "print((bug_report_counts/total_sum)*100,\"%\",\"bug_report\")\n",
        "print((improvement_request_counts/total_sum)*100,\"%\",\"improvement_request\")\n",
        "print((rating_counts/total_sum)*100,\"%\",\"rating\")\n",
        "print((others_counts/total_sum)*100,\"%\",\"others\")\n",
        "#print(df['Label'].value_counts(normalize=True))\n",
        "\n",
        "# Plot review length histogram\n",
        "plt.figure()\n",
        "df['review_length'].hist(bins=100)\n",
        "plt.title('Histogram of Review Length')\n",
        "plt.xlabel('Characters')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "# we have a review with 3023 charecters, we could remove!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aA6B5b0YCyg0",
        "outputId": "57c41a30-c936-403a-f8c1-d6b40ab56681"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                              review  bug_report  \\\n",
              "0                                 يبيله تصليحات كثير           1   \n",
              "1                  ماتحملت ابدددددا ونا دفعت فلوس 🤔😕           0   \n",
              "2  اتمنى منكم عمل خيار لتفضيل المسلسل بالكامل عوض...           0   \n",
              "3      ممتاز وبسيط وتشغيله لا يؤثر على سرعة الانترنت           0   \n",
              "4                                تبين م لي ي تم ل يب           0   \n",
              "\n",
              "   improvement_request  rating  others  \n",
              "0                    1       1       0  \n",
              "1                    1       1       1  \n",
              "2                    1       1       0  \n",
              "3                    0       1       0  \n",
              "4                    0       1       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6565a68b-2c0c-4f72-a803-124cb152f384\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>bug_report</th>\n",
              "      <th>improvement_request</th>\n",
              "      <th>rating</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يبيله تصليحات كثير</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ماتحملت ابدددددا ونا دفعت فلوس 🤔😕</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>اتمنى منكم عمل خيار لتفضيل المسلسل بالكامل عوض...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ممتاز وبسيط وتشغيله لا يؤثر على سرعة الانترنت</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>تبين م لي ي تم ل يب</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6565a68b-2c0c-4f72-a803-124cb152f384')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6565a68b-2c0c-4f72-a803-124cb152f384 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6565a68b-2c0c-4f72-a803-124cb152f384');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-636380b2-978b-450e-9135-b83b94f91cba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-636380b2-978b-450e-9135-b83b94f91cba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-636380b2-978b-450e-9135-b83b94f91cba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# we have a review with 3023 charecters, we could remove!\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u0645\\u0627\\u062a\\u062d\\u0645\\u0644\\u062a \\u0627\\u0628\\u062f\\u062f\\u062f\\u062f\\u062f\\u0627 \\u0648\\u0646\\u0627 \\u062f\\u0641\\u0639\\u062a \\u0641\\u0644\\u0648\\u0633 \\ud83e\\udd14\\ud83d\\ude15\",\n          \"\\u062a\\u0628\\u064a\\u0646 \\u0645 \\u0644\\u064a \\u064a \\u062a\\u0645 \\u0644 \\u064a\\u0628\",\n          \"\\u0627\\u062a\\u0645\\u0646\\u0649 \\u0645\\u0646\\u0643\\u0645 \\u0639\\u0645\\u0644 \\u062e\\u064a\\u0627\\u0631 \\u0644\\u062a\\u0641\\u0636\\u064a\\u0644 \\u0627\\u0644\\u0645\\u0633\\u0644\\u0633\\u0644 \\u0628\\u0627\\u0644\\u0643\\u0627\\u0645\\u0644 \\u0639\\u0648\\u0636\\u0627\\u064b \\u0639\\u0646 \\u062a\\u0641\\u0636\\u064a\\u0644 \\u0627\\u0644\\u062d\\u0644\\u0642\\u0627\\u062a \\u0641\\u0642\\u0637\\n\\u0648\\u0634\\u0643\\u0631\\u0627\\u064b\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bug_report\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"improvement_request\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"others\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: 2900 rows, 5 columns\n",
            "\n",
            "Data types:\n",
            "review                 object\n",
            "bug_report              int64\n",
            "improvement_request     int64\n",
            "rating                  int64\n",
            "others                  int64\n",
            "dtype: object\n",
            "\n",
            "Missing values per column:\n",
            "review                 0\n",
            "bug_report             0\n",
            "improvement_request    0\n",
            "rating                 0\n",
            "others                 0\n",
            "dtype: int64\n",
            "\n",
            "Review length summary:\n",
            "count    2900.000000\n",
            "mean       74.374828\n",
            "std        87.071689\n",
            "min        10.000000\n",
            "25%        34.000000\n",
            "50%        52.000000\n",
            "75%        85.000000\n",
            "max      3023.000000\n",
            "Name: review_length, dtype: float64\n",
            "        bug_report  improvement_request       rating       others  \\\n",
            "count  2900.000000          2900.000000  2900.000000  2900.000000   \n",
            "mean      0.401379             0.380345     0.679655     0.282759   \n",
            "std       0.490262             0.485555     0.466690     0.450418   \n",
            "min       0.000000             0.000000     0.000000     0.000000   \n",
            "25%       0.000000             0.000000     0.000000     0.000000   \n",
            "50%       0.000000             0.000000     1.000000     0.000000   \n",
            "75%       1.000000             1.000000     1.000000     1.000000   \n",
            "max       1.000000             1.000000     1.000000     1.000000   \n",
            "\n",
            "       review_length  \n",
            "count    2900.000000  \n",
            "mean       74.374828  \n",
            "std        87.071689  \n",
            "min        10.000000  \n",
            "25%        34.000000  \n",
            "50%        52.000000  \n",
            "75%        85.000000  \n",
            "max      3023.000000  \n",
            "\n",
            "Class distribution:\n",
            "1164 bug_report\n",
            "1103 improvement_request\n",
            "1971 rating\n",
            "820 others\n",
            "As precentages\n",
            "23.013048635824436 % bug_report\n",
            "21.80703835508106 % improvement_request\n",
            "38.967971530249116 % rating\n",
            "16.211941478845393 % others\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a from-scratch model\n",
        "o (RNN-based model: LSTM/GRU/Bidirectional/stacked/…)"
      ],
      "metadata": {
        "id": "jWIXRyw8C0fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    hamming_loss,\n",
        "    accuracy_score,\n",
        "    ConfusionMatrixDisplay,\n",
        "    multilabel_confusion_matrix\n",
        ")\n",
        "\n",
        "def eval_and_report_multilabel(model, seq, true_y, label_names, threshold=0.5):\n",
        "    # 1) Predict probabilities and binarize\n",
        "    preds_proba = model.predict(seq)\n",
        "    preds = (preds_proba >= threshold).astype(int)\n",
        "\n",
        "    # 2) Per‐label reports\n",
        "    cms = multilabel_confusion_matrix(true_y, preds)\n",
        "    print(cms)\n",
        "    # for idx, label in enumerate(label_cols):\n",
        "    #     disp = ConfusionMatrixDisplay(cms[idx],\n",
        "    #                                   display_labels=['negative','positive'])\n",
        "    #     disp.plot(cmap=plt.cm.Blues)\n",
        "    #     plt.title(label)\n",
        "    #     plt.show()\n",
        "    # 3) Overall multilabel metrics\n",
        "    print(\"\\n=== Overall Multilabel Metrics ===\")\n",
        "    print(f\"Hamming Loss:    {hamming_loss(true_y, preds):.4f}\")\n",
        "    print(f\"Subset Accuracy: {accuracy_score(true_y, preds):.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# This returns an array of shape (n_labels, 2, 2)\n",
        "# where for each label i: cm[i] = [[TN, FP],\n",
        "#                                [FN, TP]]\n",
        "#cms = multilabel_confusion_matrix(y_true, y_pred_bin)\n"
      ],
      "metadata": {
        "id": "ioUg3YkRJl55"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "label_cols = [\"bug_report\",\t\"improvement_request\",\t\"rating\",\t\"others\"]\n",
        "df_train = pd.read_csv('train_multi.csv')\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = df_train[label_cols]\n",
        "\n",
        "df_val = pd.read_csv('val_multi.csv')\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = df_val[label_cols]\n",
        "\n",
        "df_test = pd.read_csv('test_multi.csv')\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = df_test[label_cols]\n",
        "\n",
        "# 2) Identify text & one-hot columns\n",
        "# text_col   = 'review'\n",
        "\n",
        "\n",
        "# # 3) Prepare X and y\n",
        "# texts = df[text_col].astype(str).tolist()\n",
        "# y     = df[label_cols].values             # shape (n_samples, 4)\n",
        "# y_int = np.argmax(y, axis=1)              # integer labels for metrics/stratify\n",
        "\n",
        "# # 4) Decide whether we can stratify\n",
        "# counts = np.bincount(y_int)\n",
        "# strat_arg = y_int if counts.min() >= 2 else None\n",
        "\n",
        "# # 5) Split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     texts, y, test_size=0.2,\n",
        "#     stratify=strat_arg,\n",
        "#     random_state=777\n",
        "# )\n",
        "# X_train, X_val, y_train, y_val = train_test_split(\n",
        "#     X_train, y_train, test_size=0.15,\n",
        "#     random_state=777\n",
        "# )\n",
        "\n",
        "\n",
        "# 6) Tokenize & pad\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN   = 600\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "train_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_train),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "val_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_val),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "test_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_test),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "\n",
        "# 7) Build & compile the model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(label_cols), activation='softmax')\n",
        "])\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "# 8) Train\n",
        "history = model.fit(\n",
        "    train_seq, np.array(y_train),\n",
        "    validation_data=(val_seq, np.array(y_val)),\n",
        "    epochs=25, batch_size=64, callbacks=callbacks\n",
        ")\n",
        "\n",
        "eval_and_report_multilabel(\n",
        "    model,\n",
        "    seq=test_seq,\n",
        "    true_y=y_test,\n",
        "    label_names=label_cols,\n",
        "    threshold=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O-U9FBCeHMYX",
        "outputId": "88391a0c-2b42-4edb-a56f-5239c944b076"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.3368 - loss: 2.4457 - val_accuracy: 0.3103 - val_loss: 2.5901\n",
            "Epoch 2/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3178 - loss: 3.0511 - val_accuracy: 0.3103 - val_loss: 2.6881\n",
            "Epoch 3/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3089 - loss: 3.2939 - val_accuracy: 0.3103 - val_loss: 2.6108\n",
            "Epoch 4/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3290 - loss: 3.2337 - val_accuracy: 0.3103 - val_loss: 2.6693\n",
            "Epoch 5/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.2929 - loss: 3.4274 - val_accuracy: 0.3103 - val_loss: 2.6927\n",
            "Epoch 6/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3341 - loss: 3.2310 - val_accuracy: 0.3103 - val_loss: 2.6642\n",
            "Epoch 7/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3062 - loss: 3.3709 - val_accuracy: 0.3103 - val_loss: 2.7573\n",
            "Epoch 8/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3461 - loss: 3.2902 - val_accuracy: 0.3103 - val_loss: 2.6192\n",
            "Epoch 9/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3117 - loss: 3.2557 - val_accuracy: 0.3103 - val_loss: 2.6325\n",
            "Epoch 10/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3306 - loss: 3.2649 - val_accuracy: 0.3103 - val_loss: 2.6072\n",
            "Epoch 11/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3396 - loss: 3.1017 - val_accuracy: 0.3103 - val_loss: 2.6151\n",
            "Epoch 12/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3174 - loss: 3.2515 - val_accuracy: 0.3103 - val_loss: 2.6951\n",
            "Epoch 13/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3133 - loss: 3.2398 - val_accuracy: 0.3103 - val_loss: 2.6022\n",
            "Epoch 14/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3447 - loss: 3.1208 - val_accuracy: 0.3103 - val_loss: 2.6790\n",
            "Epoch 15/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3254 - loss: 3.1454 - val_accuracy: 0.3103 - val_loss: 2.6482\n",
            "Epoch 16/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3448 - loss: 3.1876 - val_accuracy: 0.3103 - val_loss: 2.6219\n",
            "Epoch 17/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.3538 - loss: 3.1360 - val_accuracy: 0.3103 - val_loss: 2.5955\n",
            "Epoch 18/25\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.3325 - loss: 3.1355 - val_accuracy: 0.3103 - val_loss: 2.5491\n",
            "Epoch 19/25\n",
            "\u001b[1m11/31\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3132 - loss: 3.3168"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0b76d1fb8342>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# 8) Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mtrain_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the best embedding from Part-B"
      ],
      "metadata": {
        "id": "j_InJwBKC5wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification analysis and possible improvements."
      ],
      "metadata": {
        "id": "pkvECUJdC7h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import pickle\n",
        "\n",
        "label_cols = [\"bug_report\",\t\"improvement_request\",\t\"rating\",\t\"others\"]\n",
        "df_train = pd.read_csv('train_multi.csv')\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = df_train[label_cols].values.astype(int)\n",
        "\n",
        "df_val = pd.read_csv('val_multi.csv')\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = df_val[label_cols].values.astype(int)\n",
        "\n",
        "df_test = pd.read_csv('test_multi.csv')\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = df_test[label_cols].values.astype(int)\n",
        "\n",
        "# TEXT PREPROCESSING\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN    = 600\n",
        "\n",
        "# Convert texts to padded sequences\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_train),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "val_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_val),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "test_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_test),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "\n",
        "# 4) EMBEDDING MATRIX LOADING\n",
        "# Assumes you exported embedding_matrix.npy from Part B\n",
        "EMBEDDING_PATH = 'tweets_cbow_300.wv.vectors.npy'\n",
        "embedding_matrix = np.load(EMBEDDING_PATH)\n",
        "print(f'\\nLoaded embedding matrix: {embedding_matrix.shape}')\n",
        "\n",
        "# 5) BUILD RNN-BASED MULTILABEL MODEL\n",
        "vocab_size, embedding_dim = embedding_matrix.shape\n",
        "num_labels = y_train.shape[1]\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_labels, activation='sigmoid', name='output')\n",
        "])\n",
        "# model = Sequential([\n",
        "#     Embedding(\n",
        "#         input_dim=vocab_size,\n",
        "#         output_dim=embedding_dim,\n",
        "#         weights=[embedding_matrix],\n",
        "#         input_length=MAX_SEQ_LEN,\n",
        "#         trainable=False,\n",
        "#         name='embedding'\n",
        "#     ),\n",
        "#     Bidirectional(\n",
        "#         LSTM(128, return_sequences=False, recurrent_dropout=0.2),\n",
        "#         name='bilstm'\n",
        "#     ),\n",
        "#     Dropout(0.3, name='dropout_1'),\n",
        "#     Dense(64, activation='relu', name='dense_1'),\n",
        "#     Dropout(0.3, name='dropout_2'),\n",
        "#     Dense(num_labels, activation='sigmoid', name='output')\n",
        "# ], name='multilabel_rnn')\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# 6) TRAIN\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "history = model.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "eval_and_report_multilabel(\n",
        "    model,\n",
        "    seq=test_seq,\n",
        "    true_y=y_test,\n",
        "    label_names=label_cols,\n",
        "    threshold=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        },
        "id": "swITicRgNlLI",
        "outputId": "84292251-fa43-4592-9cba-f832db3b98eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded embedding matrix: (331679, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.3291 - loss: 0.6496 - val_accuracy: 0.3103 - val_loss: 0.6238\n",
            "Epoch 2/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.3902 - loss: 0.5821 - val_accuracy: 0.5690 - val_loss: 0.5409\n",
            "Epoch 3/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6323 - loss: 0.4481 - val_accuracy: 0.5747 - val_loss: 0.4877\n",
            "Epoch 4/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7045 - loss: 0.3044 - val_accuracy: 0.5747 - val_loss: 0.5278\n",
            "Epoch 5/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7308 - loss: 0.2086 - val_accuracy: 0.5575 - val_loss: 0.5638\n",
            "Epoch 6/20\n",
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7150 - loss: 0.1409 - val_accuracy: 0.5316 - val_loss: 0.6585\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "[[[279  62]\n",
            "  [ 55 184]]\n",
            "\n",
            " [[237 105]\n",
            "  [ 66 172]]\n",
            "\n",
            " [[113  83]\n",
            "  [ 53 331]]\n",
            "\n",
            " [[404  17]\n",
            "  [125  34]]]\n",
            "\n",
            "=== Overall Multilabel Metrics ===\n",
            "Hamming Loss:    0.2440\n",
            "Subset Accuracy: 0.3569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With augmentation"
      ],
      "metadata": {
        "id": "ObVeA4HUrlUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import pickle\n",
        "\n",
        "label_cols = [\"bug_report\",\t\"improvement_request\",\t\"rating\",\t\"others\"]\n",
        "df_train = pd.read_csv('train_multi_aug.csv')\n",
        "X_train = df_train['review'].astype(str).tolist()\n",
        "y_train = df_train[label_cols].values.astype(int)\n",
        "\n",
        "df_val = pd.read_csv('val_multi.csv')\n",
        "X_val = df_val['review'].astype(str).tolist()\n",
        "y_val = df_val[label_cols].values.astype(int)\n",
        "\n",
        "df_test = pd.read_csv('test_multi.csv')\n",
        "X_test = df_test['review'].astype(str).tolist()\n",
        "y_test = df_test[label_cols].values.astype(int)\n",
        "\n",
        "# TEXT PREPROCESSING\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN    = 600\n",
        "\n",
        "# Convert texts to padded sequences\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_train),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "val_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_val),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "test_seq = pad_sequences(\n",
        "    tokenizer.texts_to_sequences(X_test),\n",
        "    maxlen=MAX_LEN, padding='post'\n",
        ")\n",
        "\n",
        "# 4) EMBEDDING MATRIX LOADING\n",
        "# Assumes you exported embedding_matrix.npy from Part B\n",
        "EMBEDDING_PATH = 'tweets_cbow_300.wv.vectors.npy'\n",
        "embedding_matrix = np.load(EMBEDDING_PATH)\n",
        "print(f'\\nLoaded embedding matrix: {embedding_matrix.shape}')\n",
        "\n",
        "# 5) BUILD RNN-BASED MULTILABEL MODEL\n",
        "vocab_size, embedding_dim = embedding_matrix.shape\n",
        "num_labels = y_train.shape[1]\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=MAX_VOCAB, output_dim=128, input_length=MAX_LEN),\n",
        "    Bidirectional(LSTM(64, return_sequences=False)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_labels, activation='sigmoid', name='output')\n",
        "])\n",
        "# model = Sequential([\n",
        "#     Embedding(\n",
        "#         input_dim=vocab_size,\n",
        "#         output_dim=embedding_dim,\n",
        "#         weights=[embedding_matrix],\n",
        "#         input_length=MAX_SEQ_LEN,\n",
        "#         trainable=False,\n",
        "#         name='embedding'\n",
        "#     ),\n",
        "#     Bidirectional(\n",
        "#         LSTM(128, return_sequences=False, recurrent_dropout=0.2),\n",
        "#         name='bilstm'\n",
        "#     ),\n",
        "#     Dropout(0.3, name='dropout_1'),\n",
        "#     Dense(64, activation='relu', name='dense_1'),\n",
        "#     Dropout(0.3, name='dropout_2'),\n",
        "#     Dense(num_labels, activation='sigmoid', name='output')\n",
        "# ], name='multilabel_rnn')\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "# 6) TRAIN\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=3,              # stop after 3 epochs w/o improvement\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "]\n",
        "history = model.fit(\n",
        "    train_seq, y_train,\n",
        "    validation_data=(val_seq, y_val),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "eval_and_report_multilabel(\n",
        "    model,\n",
        "    seq=test_seq,\n",
        "    true_y=y_test,\n",
        "    label_names=label_cols,\n",
        "    threshold=0.5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "4tupBPjtrnZ1",
        "outputId": "77258fed-7866-4974-da82-e647553f61d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loaded embedding matrix: (331679, 300)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 41ms/step - accuracy: 0.2694 - loss: 0.6195 - val_accuracy: 0.4684 - val_loss: 0.5921\n",
            "Epoch 2/20\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5193 - loss: 0.2090 - val_accuracy: 0.4655 - val_loss: 0.7991\n",
            "Epoch 3/20\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5645 - loss: 0.0506 - val_accuracy: 0.4511 - val_loss: 0.8362\n",
            "Epoch 4/20\n",
            "\u001b[1m137/137\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 39ms/step - accuracy: 0.5570 - loss: 0.0265 - val_accuracy: 0.4598 - val_loss: 1.0996\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
            "[[[301  40]\n",
            "  [  6 233]]\n",
            "\n",
            " [[255  87]\n",
            "  [ 41 197]]\n",
            "\n",
            " [[190   6]\n",
            "  [ 15 369]]\n",
            "\n",
            " [[356  65]\n",
            "  [ 17 142]]]\n",
            "\n",
            "=== Overall Multilabel Metrics ===\n",
            "Hamming Loss:    0.1194\n",
            "Subset Accuracy: 0.5707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-D [15 points]: Multiclass App Review Classification: Finetune an MLM\n"
      ],
      "metadata": {
        "id": "qRmq2lmTC853"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune a Bert-type model like Arabert or Marbert"
      ],
      "metadata": {
        "id": "N1JCCl2FC-ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the AraBERT preprocessor\n",
        "!pip install arabert\n",
        "\n",
        "# install Farasa (required by the preprocessor for v1 & v2 tokenization)\n",
        "!pip install farasapy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IabK648LhxLD",
        "outputId": "235c210a-d575-4160-f086-112a9fc2b505"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arabert\n",
            "  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting PyArabic (from arabert)\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting farasapy (from arabert)\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting emoji==1.4.2 (from arabert)\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (4.67.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from PyArabic->arabert) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (2025.4.26)\n",
            "Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186456 sha256=592343686a79dc140f100f592787a145cec0685381646eeae8a3dc7755b51253\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/08/b4/78657b1541bb704b088317b52429ee4016d9888fe47dbb130f\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, PyArabic, farasapy, arabert\n",
            "Successfully installed PyArabic-0.6.15 arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n",
            "Requirement already satisfied: farasapy in /usr/local/lib/python3.11/dist-packages (0.0.14)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farasapy) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farasapy) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from arabert.preprocess import ArabertPreprocessor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from transformers import TrainingArguments"
      ],
      "metadata": {
        "id": "-Y63HfefuXu7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tok = AutoTokenizer.from_pretrained('aubmindlab/bert-large-arabertv2')\n",
        "print(\"Training Sentence Lengths: \")\n",
        "df = pd.read_csv('/content/App Reviews-SingleLabel-Multiclass.csv')\n",
        "plt.hist([ len(tok.tokenize(sentence)) for sentence in df['review'].to_list()],bins=range(0,300,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "8vEOC-Lgi0Ym",
        "outputId": "63f4a263-3e75-4090-efde-b3c13c62b03a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1008 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Sentence Lengths: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0.,  28., 132., 195., 274., 307., 264., 217., 189., 166., 146.,\n",
              "        129., 102.,  86.,  57.,  69.,  41.,  40.,  47.,  26.,  36.,  33.,\n",
              "         26.,  22.,  33.,  26.,  12.,  20.,  18.,  10.,   9.,   8.,  12.,\n",
              "          9.,  10.,  11.,   5.,   3.,   7.,   7.,   3.,   1.,   4.,   0.,\n",
              "          1.,   0.,   3.,   2.,   4.,   2.,   2.,   3.,   1.,   2.,   2.,\n",
              "          0.,   4.,   5.,   1.,   1.,   1.,   3.,   1.,   0.,   0.,   0.,\n",
              "          0.,   1.,   0.,   2.,   0.,   5.,   2.,   1.,   2.,   2.,   0.,\n",
              "          1.,   1.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
              "          0.,   0.,   0.,   0.,   0.,   0.]),\n",
              " array([  0.,   2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,\n",
              "         22.,  24.,  26.,  28.,  30.,  32.,  34.,  36.,  38.,  40.,  42.,\n",
              "         44.,  46.,  48.,  50.,  52.,  54.,  56.,  58.,  60.,  62.,  64.,\n",
              "         66.,  68.,  70.,  72.,  74.,  76.,  78.,  80.,  82.,  84.,  86.,\n",
              "         88.,  90.,  92.,  94.,  96.,  98., 100., 102., 104., 106., 108.,\n",
              "        110., 112., 114., 116., 118., 120., 122., 124., 126., 128., 130.,\n",
              "        132., 134., 136., 138., 140., 142., 144., 146., 148., 150., 152.,\n",
              "        154., 156., 158., 160., 162., 164., 166., 168., 170., 172., 174.,\n",
              "        176., 178., 180., 182., 184., 186., 188., 190., 192., 194., 196.,\n",
              "        198., 200., 202., 204., 206., 208., 210., 212., 214., 216., 218.,\n",
              "        220., 222., 224., 226., 228., 230., 232., 234., 236., 238., 240.,\n",
              "        242., 244., 246., 248., 250., 252., 254., 256., 258., 260., 262.,\n",
              "        264., 266., 268., 270., 272., 274., 276., 278., 280., 282., 284.,\n",
              "        286., 288., 290., 292., 294., 296., 298.]),\n",
              " <BarContainer object of 149 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Truncated training sequences: \", sum([len(tok.tokenize(sentence)) > 200 for sentence in df['review'].to_list()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZUySQAsjbHY",
        "outputId": "5ba3b30c-3d99-40fa-c309-e4d05a28e41a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truncated training sequences:  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        'accuracy': accuracy_score(labels, preds),\n",
        "        **{f'{lab}_f1': score\n",
        "           for lab, score in\n",
        "           zip(label_names,\n",
        "               __import__('sklearn.metrics').metrics.f1_score(\n",
        "                   labels, preds, average=None\n",
        "               ))\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "Rx1OpLfCxD28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_val = pd.read_csv('val.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_train['Label'] = le.fit_transform(df_train['Label'])\n",
        "# now transform val & test\n",
        "df_val  ['Label'] = le.transform(df_val['Label'])\n",
        "df_test ['Label'] = le.transform(df_test['Label'])\n",
        "label_names = le.classes_\n",
        "# Dataset class to feed into AraBert\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# create dataset and get tokenizer ( pretrained )\n",
        "MODEL_NAME = 'aubmindlab/bert-large-arabertv2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_ds = ReviewDataset(\n",
        "    df_train['review'].tolist(),\n",
        "    df_train['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "val_ds = ReviewDataset(\n",
        "    df_val['review'].tolist(),\n",
        "    df_val['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "test_ds = ReviewDataset(\n",
        "    df_test['review'].tolist(),\n",
        "    df_test['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# build the MLM\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "# training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./bert_reviews',\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "    # enable training & evaluation\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "\n",
        "    # run eval and saving at the end of each epoch\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,        # keep only the best/last checkpoint\n",
        "\n",
        "    # core hyperparameters\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # log every 100 steps\n",
        "    logging_strategy='steps',\n",
        "    logging_steps=100,\n",
        "\n",
        "    # pick up the best model automatically\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    greater_is_better=True,\n",
        ")\n",
        "# 8) TRAINER\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,        # ← pad to max length in each batch\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 9) RUN TRAINING\n",
        "trainer.train()\n",
        "\n",
        "# 10) EVALUATION\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "d6yLQBymC9oN",
        "outputId": "b4eec0ea-e0a2-4b5e-de7d-a2fe5241c1b6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-large-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-38-00c77c4266bc>:92: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='869' max='1240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 869/1240 04:07 < 01:45, 3.50 it/s, Epoch 7/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Bug Report F1</th>\n",
              "      <th>Improvement Request F1</th>\n",
              "      <th>Others F1</th>\n",
              "      <th>Rating F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.247300</td>\n",
              "      <td>1.302875</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.303900</td>\n",
              "      <td>1.273953</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.317100</td>\n",
              "      <td>1.273474</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.303200</td>\n",
              "      <td>1.275692</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.291900</td>\n",
              "      <td>1.272870</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.291800</td>\n",
              "      <td>1.277792</td>\n",
              "      <td>0.448276</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.619048</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 2/11 00:00 < 00:00, 9.36 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-00c77c4266bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# 9) RUN TRAINING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# 10) EVALUATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2662\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3094\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3096\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3097\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3044\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3045\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3046\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3047\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4153\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4154\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4155\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4156\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4368\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4369\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4370\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4371\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4372\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_logits_for_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2811\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2812\u001b[0m         \"\"\"\n\u001b[0;32m-> 2813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munwrap_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_fp32_wrapper\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_torch_compile\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDistributedOperationException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{function.__module__}.{function.__name__}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     return recursively_apply(\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         )\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtest_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0merror_on_other_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;31m# Then pad to the maximum size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(test_ds)\n",
        "preds = np.argmax(preds_output.predictions, axis=-1)\n",
        "print(classification_report(df_test['Label'], preds, target_names=[str(l) for l in label_names]))"
      ],
      "metadata": {
        "id": "kV2hp2PKxlYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With Augmentation"
      ],
      "metadata": {
        "id": "NOJ59kv7w9dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "df_train = pd.read_csv('train_augmented.csv')\n",
        "df_val = pd.read_csv('val.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "df_train['Label'] = le.fit_transform(df_train['Label'])\n",
        "# now transform val & test\n",
        "df_val  ['Label'] = le.transform(df_val['Label'])\n",
        "df_test ['Label'] = le.transform(df_test['Label'])\n",
        "label_names = le.classes_\n",
        "# Dataset class to feed into AraBert\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# create dataset and get tokenizer ( pretrained )\n",
        "MODEL_NAME = 'aubmindlab/bert-large-arabertv2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "train_ds = ReviewDataset(\n",
        "    df_train['review'].tolist(),\n",
        "    df_train['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "val_ds = ReviewDataset(\n",
        "    df_val['review'].tolist(),\n",
        "    df_val['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "test_ds = ReviewDataset(\n",
        "    df_test['review'].tolist(),\n",
        "    df_test['Label'].tolist(),\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# build the MLM\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "\n",
        "# training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./bert_reviews',\n",
        "    overwrite_output_dir=True,\n",
        "\n",
        "    # enable training & evaluation\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "\n",
        "    # run eval and saving at the end of each epoch\n",
        "    eval_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=1,        # keep only the best/last checkpoint\n",
        "\n",
        "    # core hyperparameters\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "\n",
        "    # log every 100 steps\n",
        "    logging_strategy='steps',\n",
        "    logging_steps=100,\n",
        "\n",
        "    # pick up the best model automatically\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='accuracy',\n",
        "    greater_is_better=True,\n",
        ")\n",
        "# 8) TRAINER\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,        # ← pad to max length in each batch\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# 9) RUN TRAINING\n",
        "trainer.train()\n",
        "\n",
        "# 10) EVALUATION\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "CNxBoC6Zw86p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification analysis and possible improvements."
      ],
      "metadata": {
        "id": "Vo3MKwTlC_XV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part-E [15 points]: Multilabel App Review Classification: Finetune an MLM"
      ],
      "metadata": {
        "id": "j73dzo7BDAtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-tune a Bert-type model like Arabert or Marbert"
      ],
      "metadata": {
        "id": "X_TlbGZ9DC9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "\n",
        "df_train = pd.read_csv('train_multi.csv')\n",
        "df_val = pd.read_csv('val_multi.csv')\n",
        "df_test = pd.read_csv('test_multi.csv')\n",
        "\n",
        "\n",
        "TEXT_COL = \"review\"\n",
        "LABEL_COLS = ['bug_report','improvement_request','rating','others']\n",
        "num_labels = len(LABEL_COLS)\n",
        "\n",
        "# ensure label columns are ints 0/1\n",
        "df_train[LABEL_COLS] = df_train[LABEL_COLS].astype(int)\n",
        "df_val[LABEL_COLS]   = df_val[LABEL_COLS].astype(int)\n",
        "df_test[LABEL_COLS]  = df_test[LABEL_COLS].astype(int)\n",
        "\n",
        "\n",
        "# AraBERT preprocessing\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "prep = ArabertPreprocessor('aubmindlab/bert-base-arabertv2')\n",
        "for df_ in (df_train, df_val, df_test):\n",
        "    df_['review'] = df_['review'].apply(prep.preprocess)\n",
        "\n",
        "MODEL_NAME = 'aubmindlab/bert-base-arabertv2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "class ReviewDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer):\n",
        "        self.texts     = texts\n",
        "        self.labels    = labels\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # tokenize the text\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=False,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        # convert label row to float\n",
        "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        # HuggingFace Trainer will pick up encoding[\"labels\"]\n",
        "        encoding[\"labels\"] = label_tensor\n",
        "        # remove the extra batch dim\n",
        "        return {k: v.squeeze(0) for k, v in encoding.items()}\n",
        "\n",
        "train_ds = ReviewDataset(df_train[TEXT_COL].tolist(),\n",
        "                         df_train[LABEL_COLS].values,\n",
        "                         tokenizer)\n",
        "val_ds   = ReviewDataset(df_val[TEXT_COL].tolist(),\n",
        "                         df_val[LABEL_COLS].values,\n",
        "                         tokenizer)\n",
        "test_ds  = ReviewDataset(test_df[TEXT_COL].tolist(),\n",
        "                         df_test[LABEL_COLS].values,\n",
        "                         tokenizer)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "# model (multilabel)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=num_labels,\n",
        "    problem_type=\"multi_label_classification\"  # triggers BCEWithLogitsLoss\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./bert_multilabel\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=3,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"micro_f1\",\n",
        "    greater_is_better=True,\n",
        ")\n",
        "\n",
        "# metric\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits)).numpy()\n",
        "    preds = (probs >= 0.5).astype(int)\n",
        "    labels = labels.astype(int)\n",
        "\n",
        "    micro_f1 = f1_score(labels, preds, average=\"micro\")\n",
        "    macro_f1 = f1_score(labels, preds, average=\"macro\")\n",
        "    subset_acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"micro_f1\": micro_f1,\n",
        "        \"macro_f1\": macro_f1,\n",
        "        \"subset_accuracy\": subset_acc\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train and evaluate\n",
        "trainer.train()\n",
        "print(trainer.evaluate())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "id": "fyg5XzoMDAU8",
        "outputId": "cad46e0b-5099-4891-bc7a-9217715912d6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[2025-05-10 20:57:13,611 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-41-fb078ec4d4f2>:119: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='372' max='372' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [372/372 00:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Subset Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.524000</td>\n",
              "      <td>0.420179</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.746157</td>\n",
              "      <td>0.479885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.389500</td>\n",
              "      <td>0.388721</td>\n",
              "      <td>0.790861</td>\n",
              "      <td>0.739413</td>\n",
              "      <td>0.517241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.323800</td>\n",
              "      <td>0.377240</td>\n",
              "      <td>0.812715</td>\n",
              "      <td>0.773404</td>\n",
              "      <td>0.545977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.377239853143692, 'eval_micro_f1': 0.8127147766323024, 'eval_macro_f1': 0.7734035221658015, 'eval_subset_accuracy': 0.5459770114942529, 'eval_runtime': 0.5975, 'eval_samples_per_second': 582.466, 'eval_steps_per_second': 18.411, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['bug_report', 'improvement_request', 'rating', 'others'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-fb078ec4d4f2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m print(classification_report(\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABEL_COLS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLABEL_COLS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m ))\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['bug_report', 'improvement_request', 'rating', 'others'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification analysis and possible improvements."
      ],
      "metadata": {
        "id": "cmXKBqbhDEW5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cl8aFEl8DD_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}